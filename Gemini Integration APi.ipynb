{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e01d5ce-5bf5-4969-8af5-5ff38efa042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ee64e5d-838b-4853-b3d2-0dea14f17af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key='AIzaSyCABGD7ZfFR4_OCJW2CpLvx_97E8fCv_24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd66da92-3060-4c28-831a-5e6f3e5f3c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## The AI & API Synergy: Building the Future, One API Call at a Time\n",
      "\n",
      "The relationship between AI and APIs is like a perfectly choreographed dance, with each partner enhancing the other. Here's a glimpse into the fascinating synergy they share:\n",
      "\n",
      "**1. AI as a Service, Delivered Through APIs:** \n",
      "Imagine you're building a website that needs to translate text in real-time. Instead of developing your own complex translation algorithm, you can simply use a translation API powered by AI. This lets you tap into the immense power of cutting-edge AI models without having to worry about the technical complexities.\n",
      "\n",
      "**2. APIs as the Backbone of AI Development:**\n",
      "AI models require massive datasets for training and refinement. APIs provide the pipeline for collecting, sharing, and accessing this data, enabling researchers and developers to build more powerful and sophisticated AI models. Think of it like a global network where data flows freely, fueling the growth of AI.\n",
      "\n",
      "**3. Democratizing AI with APIs:** \n",
      "APIs act as bridges, connecting developers with AI tools and resources. This democratization allows anyone, regardless of their technical expertise, to integrate AI capabilities into their applications. Imagine the possibilities for small businesses and individuals who can now leverage powerful AI solutions.\n",
      "\n",
      "**4. The Future of AI is API-Driven:** \n",
      "AI is increasingly becoming a part of our everyday lives, from personalized recommendations to automating complex tasks. APIs will play a crucial role in seamlessly integrating AI into our devices, applications, and interactions, creating a future where AI is always there to assist us.\n",
      "\n",
      "**Examples of AI & API Synergies:**\n",
      "\n",
      "* **Google Cloud AI Platform:** Provides APIs for various AI tasks, like natural language processing, image recognition, and machine learning.\n",
      "* **Amazon Rekognition:** An API that allows developers to add image and video analysis capabilities to their applications, powered by deep learning.\n",
      "* **OpenAI API:** Enables developers to access powerful language models like GPT-3, for tasks like text generation, translation, and code completion.\n",
      "\n",
      "**The Future is Bright:** \n",
      "The relationship between AI and APIs is constantly evolving, paving the way for exciting advancements in various fields. As AI continues to develop, we can expect to see even more powerful and versatile APIs that will further integrate AI into our lives, making it an integral part of our digital landscape. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(\"Write Me Some Thing Intresting About AI & API's\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6636b4a7-a857-4dae-9485-eedb69239814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The picture shows Shah Rukh Khan, a famous Indian actor, standing next to a white Rolls-Royce Cullinan. He is wearing a white t-shirt, a denim jacket, and black pants. The car has a black and white exterior and a black interior. It is a luxury SUV. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "image = PIL.Image.open(r\"C:\\Users\\ABDUL HAMEED\\OneDrive\\Desktop\\shah.jpeg\")\n",
    "response = model.generate_content([\"Tell me about this Picture and the person in it\", image])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e63c486-b7c4-4b69-9be2-7f22346fc134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's great! I love dogs. What breeds are they? Do you have any pictures you'd like to share? 😄 \n",
      "\n",
      "That's a fun question!  Since you have 2 dogs, and each dog has 4 paws, there are a total of **8** paws in your house! 🐾🐾🐾🐾🐾🐾🐾🐾 \n",
      "\n",
      "Wow, that's quite a menagerie!  Adding in your four cats, with each having four paws, that brings the total to  8 (dogs) + 16 (cats) = **24** paws in your house! 🙀🙀🙀🙀🙀🙀🙀🙀🙀🙀🙀🙀🙀🙀🙀🙀🙀🙀🙀🙀🙀🙀🙀🙀\n",
      "\n",
      "You must have a very lively and furry home! 😄 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "chat = model.start_chat(\n",
    "    history=[\n",
    "        {\"role\": \"user\", \"parts\": \"Hello\"},\n",
    "        {\"role\": \"model\", \"parts\": \"Great to meet you. What would you like to know?\"},\n",
    "    ]\n",
    ")\n",
    "response = chat.send_message(\"I have 2 dogs in my house.\")\n",
    "print(response.text)\n",
    "response = chat.send_message(\"How many paws are in my house?\")\n",
    "print(response.text)\n",
    "response = chat.send_message(\"I even have 4 cats now what\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e61e7740-5a2a-4311-8db0-05d51144e3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your message (or type 'exit' to stop):  hey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Hey there! How can I help you today? \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your message (or type 'exit' to stop):  exit\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# Start with an empty history list to store conversation\n",
    "history = []\n",
    "\n",
    "# Initialize the chat session\n",
    "chat = model.start_chat(history=history)\n",
    "\n",
    "while True:\n",
    "    # Get user input\n",
    "    user_input = input(\"Enter your message (or type 'exit' to stop): \")\n",
    "\n",
    "    # Break loop if the user wants to exit\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    # Append user input to the history\n",
    "    history.append({\"role\": \"user\", \"parts\": user_input})\n",
    "    \n",
    "    # Send the user's message to the chat and get the response\n",
    "    response = chat.send_message(user_input)\n",
    "    \n",
    "    # Append the model's response to the history\n",
    "    history.append({\"role\": \"model\", \"parts\": response.text})\n",
    "\n",
    "    # Print the response\n",
    "    print(f\"Model: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85e7087c-8470-4341-b11e-1bfc1a4f1d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'parts': 'hey'}, {'role': 'model', 'parts': 'Hey there! How can I help you today? \\n'}]\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f669e1-c533-438d-adbf-af1958c7ebff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
